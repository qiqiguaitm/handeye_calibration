#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
improve_data_quality.py - æ ‡å®šæ•°æ®è´¨é‡ç®¡ç†æ¨¡å—

æä¾›:
- æ•°æ®è´¨é‡è¿‡æ»¤å™¨ (è¿åŠ¨ä¸è¶³ã€å·¥ä½œç©ºé—´è¾¹ç•Œã€æç«¯å§¿æ€ç­‰)
- RANSACå¼‚å¸¸å€¼è¿‡æ»¤
- é‡æŠ•å½±è¯¯å·®è¿‡æ»¤

Design: Linus "Good Taste" åŸåˆ™
- æ¯ä¸ªè¿‡æ»¤å™¨æ˜¯ç‹¬ç«‹å‡½æ•°,å¯å•ç‹¬ä½¿ç”¨æˆ–ç»„åˆ
- ç»Ÿä¸€çš„è¾“å…¥/è¾“å‡ºæ ¼å¼
- å¤±è´¥æ—¶è¿”å›åŸæ•°æ®,ä¸ç ´åæµç¨‹
"""

import numpy as np
import cv2
from scipy.spatial.transform import Rotation as R
from calibration_common import normalize_angle_deg, angle_difference_deg


# ============================================================================
# æ•°æ®è´¨é‡è¿‡æ»¤å™¨
# ============================================================================

class DataQualityFilter:
    """æ•°æ®è´¨é‡è¿‡æ»¤å™¨é›†åˆ

    æ¯ä¸ªè¿‡æ»¤å™¨è¿”å› (filtered_data, removed_frames)
    """

    @staticmethod
    def filter_insufficient_motion(collected_data, min_motion_mm=5.0,
                                   min_rotation_deg=2.0, require_both=True):
        """è¿‡æ»¤è¿åŠ¨ä¸è¶³çš„å¸§

        Args:
            collected_data: é‡‡é›†æ•°æ®åˆ—è¡¨
            min_motion_mm: æœ€å°ä½ç§»(mm)
            min_rotation_deg: æœ€å°æ—‹è½¬(åº¦)
            require_both: æ˜¯å¦è¦æ±‚ä½ç§»å’Œæ—‹è½¬éƒ½æ»¡è¶³

        Returns:
            tuple: (filtered_data, removed_frames)
        """
        if len(collected_data) < 2:
            return collected_data, []

        filtered = []
        removed = []

        for i, data in enumerate(collected_data):
            if i == 0:
                filtered.append(data)
                continue

            # è®¡ç®—ä¸å‰ä¸€å¸§çš„è¿åŠ¨
            prev_pose = np.array(collected_data[i-1]['pose'])
            curr_pose = np.array(data['pose'])

            # ä½ç§» (mm)
            motion_mm = np.linalg.norm((curr_pose[:3] - prev_pose[:3]) * 1000)

            # æ—‹è½¬ (åº¦) - æ³¨æ„ï¼šposeä¸­çš„è§’åº¦æ˜¯å¼§åº¦ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸ºåº¦æ•°
            roll_diff = angle_difference_deg(np.degrees(curr_pose[3]), np.degrees(prev_pose[3]))
            pitch_diff = angle_difference_deg(np.degrees(curr_pose[4]), np.degrees(prev_pose[4]))
            yaw_diff = angle_difference_deg(np.degrees(curr_pose[5]), np.degrees(prev_pose[5]))
            rotation_deg = np.sqrt(roll_diff**2 + pitch_diff**2 + yaw_diff**2)

            # åˆ¤æ–­æ¡ä»¶
            motion_ok = motion_mm >= min_motion_mm
            rotation_ok = rotation_deg >= min_rotation_deg

            if require_both:
                passed = motion_ok and rotation_ok
            else:
                passed = motion_ok or rotation_ok

            if passed:
                filtered.append(data)
            else:
                removed.append({
                    'frame_id': data['frame_id'],
                    'motion_mm': motion_mm,
                    'rotation_deg': rotation_deg,
                    'reason': 'è¿åŠ¨ä¸è¶³'
                })

        return filtered, removed

    @staticmethod
    def filter_workspace_boundary(collected_data, boundary_margin_ratio=0.10,
                                  min_boundary_axes=1):
        """è¿‡æ»¤å·¥ä½œç©ºé—´è¾¹ç•Œçš„å¸§

        Args:
            collected_data: é‡‡é›†æ•°æ®åˆ—è¡¨
            boundary_margin_ratio: è¾¹ç•Œè£•åº¦æ¯”ä¾‹(0-1)
            min_boundary_axes: è‡³å°‘å‡ ä¸ªè½´åœ¨è¾¹ç•Œæ‰è¿‡æ»¤

        Returns:
            tuple: (filtered_data, removed_frames)
        """
        if not collected_data:
            return collected_data, []

        # è®¡ç®—å·¥ä½œç©ºé—´èŒƒå›´
        positions = np.array([data['pose'][:3] for data in collected_data])
        min_vals = positions.min(axis=0)
        max_vals = positions.max(axis=0)
        ranges = max_vals - min_vals

        filtered = []
        removed = []

        for data in collected_data:
            pos = np.array(data['pose'][:3])

            # è®¡ç®—æ¯ä¸ªè½´çš„è¾¹ç•Œè·ç¦»
            boundary_count = 0
            for axis in range(3):
                margin = ranges[axis] * boundary_margin_ratio
                if (pos[axis] - min_vals[axis]) < margin or \
                   (max_vals[axis] - pos[axis]) < margin:
                    boundary_count += 1

            if boundary_count >= min_boundary_axes:
                removed.append({
                    'frame_id': data['frame_id'],
                    'position': pos * 1000,  # mm
                    'reason': f'{boundary_count}ä¸ªè½´åœ¨è¾¹ç•Œ{boundary_margin_ratio*100:.0f}%å†…'
                })
            else:
                filtered.append(data)

        return filtered, removed

    @staticmethod
    def filter_extreme_poses(collected_data, max_pitch_deg=70.0, max_roll_deg=None,
                            max_yaw_deg=None, verbose=True):
        """è¿‡æ»¤æç«¯å§¿æ€è§’çš„å¸§ï¼ˆç›¸å¯¹äºåˆå§‹ä½å§¿çš„å˜åŒ–é‡ï¼‰

        Args:
            collected_data: é‡‡é›†æ•°æ®åˆ—è¡¨
            max_pitch_deg: æœ€å¤§å…è®¸pitchå˜åŒ–é‡(åº¦)ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
            max_roll_deg: æœ€å¤§å…è®¸rollå˜åŒ–é‡(åº¦)ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
            max_yaw_deg: æœ€å¤§å…è®¸yawå˜åŒ–é‡(åº¦)ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (filtered_data, removed_frames)
        """
        if not collected_data:
            return collected_data, []

        # å‚è€ƒä½å§¿ï¼ˆç¬¬ä¸€å¸§ï¼‰
        ref_pose = collected_data[0]['pose']
        ref_roll_deg = np.degrees(ref_pose[3])
        ref_pitch_deg = np.degrees(ref_pose[4])
        ref_yaw_deg = np.degrees(ref_pose[5])

        if verbose:
            print(f"    å‚è€ƒä½å§¿ (å¸§ {collected_data[0]['frame_id']}): Roll={ref_roll_deg:.1f}Â°, Pitch={ref_pitch_deg:.1f}Â°, Yaw={ref_yaw_deg:.1f}Â°")
            print(f"    é˜ˆå€¼: Î”Rollâ‰¤{max_roll_deg}Â°, Î”Pitchâ‰¤{max_pitch_deg}Â°, Î”Yawâ‰¤{max_yaw_deg}Â°")

        filtered = []
        removed = []
        max_diffs = {'roll': 0, 'pitch': 0, 'yaw': 0}

        for data in collected_data:
            roll, pitch, yaw = data['pose'][3:6]
            roll_deg = np.degrees(roll)
            pitch_deg = np.degrees(pitch)
            yaw_deg = np.degrees(yaw)

            # è®¡ç®—ç›¸å¯¹äºåˆå§‹ä½å§¿çš„å˜åŒ–é‡
            from calibration_common import angle_difference_deg
            pitch_diff = abs(angle_difference_deg(pitch_deg, ref_pitch_deg))
            roll_diff = abs(angle_difference_deg(roll_deg, ref_roll_deg))
            yaw_diff = abs(angle_difference_deg(yaw_deg, ref_yaw_deg))

            # è·Ÿè¸ªæœ€å¤§å˜åŒ–é‡
            max_diffs['roll'] = max(max_diffs['roll'], roll_diff)
            max_diffs['pitch'] = max(max_diffs['pitch'], pitch_diff)
            max_diffs['yaw'] = max(max_diffs['yaw'], yaw_diff)

            reasons = []
            if max_pitch_deg is not None and pitch_diff > max_pitch_deg:
                reasons.append(f'Î”Pitch={pitch_diff:.1f}Â°(>{max_pitch_deg}Â°)')
            if max_roll_deg is not None and roll_diff > max_roll_deg:
                reasons.append(f'Î”Roll={roll_diff:.1f}Â°(>{max_roll_deg}Â°)')
            if max_yaw_deg is not None and yaw_diff > max_yaw_deg:
                reasons.append(f'Î”Yaw={yaw_diff:.1f}Â°(>{max_yaw_deg}Â°)')

            if reasons:
                removed.append({
                    'frame_id': data['frame_id'],
                    'roll_deg': roll_deg,
                    'pitch_deg': pitch_deg,
                    'yaw_deg': yaw_deg,
                    'roll_diff': roll_diff,
                    'pitch_diff': pitch_diff,
                    'yaw_diff': yaw_diff,
                    'reason': ' & '.join(reasons)
                })
            else:
                filtered.append(data)

        if verbose:
            print(f"    å®é™…æœ€å¤§å˜åŒ–: Î”Roll={max_diffs['roll']:.1f}Â°, Î”Pitch={max_diffs['pitch']:.1f}Â°, Î”Yaw={max_diffs['yaw']:.1f}Â°")

        return filtered, removed

    @staticmethod
    def filter_reprojection_error(R_gripper2base, t_gripper2base, R_target2cam,
                                   t_target2cam, frame_ids, reprojection_errors,
                                   max_error_px=2.0):
        """è¿‡æ»¤é‡æŠ•å½±è¯¯å·®è¿‡å¤§çš„å¸§

        Args:
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            frame_ids: å¸§IDåˆ—è¡¨
            reprojection_errors: é‡æŠ•å½±è¯¯å·®åˆ—è¡¨
            max_error_px: æœ€å¤§å…è®¸é‡æŠ•å½±è¯¯å·®(åƒç´ )

        Returns:
            tuple: (filtered R_g, filtered t_g, filtered R_t, filtered t_t,
                    filtered frame_ids, filtered errors, removed_frames)
        """
        keep_indices = [i for i, err in enumerate(reprojection_errors) if err <= max_error_px]
        removed_indices = [i for i, err in enumerate(reprojection_errors) if err > max_error_px]

        removed_frames = [
            {
                'frame_id': frame_ids[idx],
                'reprojection_error_px': reprojection_errors[idx],
                'reason': f'Reprojection error {reprojection_errors[idx]:.3f}px > {max_error_px}px'
            }
            for idx in removed_indices
        ]

        # Filter all arrays
        R_g_filtered = [R_gripper2base[i] for i in keep_indices]
        t_g_filtered = [t_gripper2base[i] for i in keep_indices]
        R_t_filtered = [R_target2cam[i] for i in keep_indices]
        t_t_filtered = [t_target2cam[i] for i in keep_indices]
        frame_ids_filtered = [frame_ids[i] for i in keep_indices]
        errors_filtered = [reprojection_errors[i] for i in keep_indices]

        return (R_g_filtered, t_g_filtered, R_t_filtered, t_t_filtered,
                frame_ids_filtered, errors_filtered, removed_frames)

    @staticmethod
    def apply_all_filters(collected_data, config=None, verbose=True):
        """åº”ç”¨æ‰€æœ‰è´¨é‡è¿‡æ»¤å™¨

        Args:
            collected_data: åŸå§‹é‡‡é›†æ•°æ®
            config: é…ç½®å­—å…¸ï¼ˆquality_filter éƒ¨åˆ†ï¼‰ï¼ŒNone åˆ™ä½¿ç”¨é»˜è®¤å€¼
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (filtered_data, filter_report)
        """
        # é»˜è®¤é…ç½®
        if config is None:
            config = {}

        min_motion_mm = config.get('min_motion_mm', 5.0)
        min_rotation_deg = config.get('min_rotation_deg', 2.0)
        boundary_margin_ratio = config.get('boundary_margin_ratio', 0.10)
        max_pitch_deg = config.get('max_pitch_deg', 70.0)
        max_roll_deg = config.get('max_roll_deg', None)
        max_yaw_deg = config.get('max_yaw_deg', None)

        if verbose:
            print("\n" + "="*60)
            print("ğŸ” æ•°æ®è´¨é‡è¿‡æ»¤")
            print("="*60)
            print(f"åŸå§‹æ•°æ®: {len(collected_data)} å¸§")

        original_count = len(collected_data)
        all_removed = []

        # ç¬¬1å±‚ï¼šè¿‡æ»¤è¿åŠ¨ä¸è¶³çš„å¸§
        if verbose:
            print("\næ­¥éª¤1: è¿‡æ»¤è¿åŠ¨ä¸è¶³çš„å¸§")

        filtered_data, removed = DataQualityFilter.filter_insufficient_motion(
            collected_data,
            min_motion_mm=min_motion_mm,
            min_rotation_deg=min_rotation_deg,
            require_both=True
        )

        if verbose and removed:
            print(f"  ç§»é™¤ {len(removed)} å¸§ (ä½ç§»<{min_motion_mm}mm æˆ– æ—‹è½¬<{min_rotation_deg}Â°)")
        all_removed.extend(removed)

        # ç¬¬2å±‚ï¼šè¿‡æ»¤å·¥ä½œç©ºé—´è¾¹ç•Œçš„å¸§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if boundary_margin_ratio is not None and boundary_margin_ratio > 0:
            if verbose:
                print("\næ­¥éª¤2: è¿‡æ»¤å·¥ä½œç©ºé—´è¾¹ç•Œå¸§")
            filtered_data, removed = DataQualityFilter.filter_workspace_boundary(
                filtered_data,
                boundary_margin_ratio=boundary_margin_ratio,
                min_boundary_axes=1
            )

            if verbose and removed:
                print(f"  ç§»é™¤ {len(removed)} å¸§ (åœ¨è¾¹ç•Œ{boundary_margin_ratio*100:.0f}%å†…)")
            all_removed.extend(removed)
        else:
            if verbose:
                print("\næ­¥éª¤2: è·³è¿‡å·¥ä½œç©ºé—´è¾¹ç•Œè¿‡æ»¤ (å·²ç¦ç”¨)")

        # ç¬¬3å±‚ï¼šè¿‡æ»¤æç«¯å§¿æ€è§’çš„å¸§
        if verbose:
            print("\næ­¥éª¤3: è¿‡æ»¤æç«¯å§¿æ€è§’å¸§")

        filtered_data, removed = DataQualityFilter.filter_extreme_poses(
            filtered_data,
            max_pitch_deg=max_pitch_deg,
            max_roll_deg=max_roll_deg,
            max_yaw_deg=max_yaw_deg,
            verbose=True  # å¼€å¯è¯¦ç»†è¾“å‡º
        )

        if verbose:
            if removed:
                limits = []
                if max_pitch_deg is not None:
                    limits.append(f"Î”Pitch>{max_pitch_deg}Â°")
                if max_roll_deg is not None:
                    limits.append(f"Î”Roll>{max_roll_deg}Â°")
                if max_yaw_deg is not None:
                    limits.append(f"Î”Yaw>{max_yaw_deg}Â°")
                print(f"  ç§»é™¤ {len(removed)} å¸§ ({' æˆ– '.join(limits) if limits else 'æ— é™åˆ¶'})")
                # æ˜¾ç¤ºè¢«ç§»é™¤çš„å¸§è¯¦æƒ…
                for r in removed[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    âŒ å¸§ {r['frame_id']}: {r['reason']}")
                if len(removed) > 5:
                    print(f"    ... ä»¥åŠå…¶ä»– {len(removed)-5} å¸§")
            else:
                print(f"  æ— å¸§è¢«ç§»é™¤ (æ‰€æœ‰å§¿æ€å˜åŒ–åœ¨é˜ˆå€¼å†…)")
        all_removed.extend(removed)

        # ç»Ÿè®¡
        final_count = len(filtered_data)
        removed_count = original_count - final_count

        if verbose:
            print("\n" + "-"*60)
            print("ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:")
            print(f"  åŸå§‹: {original_count} å¸§")
            print(f"  ä¿ç•™: {final_count} å¸§ ({final_count/original_count*100:.1f}%)")
            print(f"  ç§»é™¤: {removed_count} å¸§ ({removed_count/original_count*100:.1f}%)")

        filter_report = {
            'original_count': original_count,
            'final_count': final_count,
            'removed_count': removed_count,
            'removed_frames': all_removed,
            'removal_rate': removed_count / original_count if original_count > 0 else 0
        }

        return filtered_data, filter_report


# ============================================================================
# RANSAC å¼‚å¸¸å€¼è¿‡æ»¤
# ============================================================================

class RANSACFilter:
    """RANSACå¼‚å¸¸å€¼è¿‡æ»¤å™¨

    ä½¿ç”¨AX=XBä¸€è‡´æ€§è¯¯å·®è¿›è¡Œé²æ£’çš„å¼‚å¸¸å€¼æ£€æµ‹
    """

    @staticmethod
    def ransac_filter_handeye(R_gripper2base, t_gripper2base, R_target2cam,
                              t_target2cam, frame_ids, threshold=6.0,
                              iterations=None, min_inlier_ratio=0.3):
        """ä½¿ç”¨RANSACè¿‡æ»¤æ‰‹çœ¼æ ‡å®šå¼‚å¸¸å€¼

        Args:
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            frame_ids: å¸§IDåˆ—è¡¨
            threshold: å†…ç‚¹é˜ˆå€¼(mm)
            iterations: RANSACè¿­ä»£æ¬¡æ•°
            min_inlier_ratio: æœ€å°å†…ç‚¹æ¯”ä¾‹

        Returns:
            list: å†…ç‚¹ç´¢å¼•åˆ—è¡¨
        """
        n_samples = len(R_gripper2base)

        if n_samples < 5:
            return list(range(n_samples))

        if iterations is None:
            iterations = min(200, n_samples * 20)

        best_inliers = []
        best_median_error = float('inf')

        for iteration in range(iterations):
            # éšæœºé‡‡æ ·8ä¸ªç‚¹
            sample_size = min(8, n_samples)
            sample_indices = np.random.choice(n_samples, sample_size, replace=False)

            try:
                # ä½¿ç”¨æ ·æœ¬è®¡ç®—æ ‡å®š
                R_sample, t_sample = cv2.calibrateHandEye(
                    [R_gripper2base[i] for i in sample_indices],
                    [t_gripper2base[i] for i in sample_indices],
                    [R_target2cam[i] for i in sample_indices],
                    [t_target2cam[i] for i in sample_indices],
                    method=cv2.CALIB_HAND_EYE_TSAI
                )

                # è®¡ç®—æ‰€æœ‰ç‚¹çš„AX=XBè¯¯å·®
                errors = []
                for i in range(n_samples):
                    # AX
                    AX_R = R_gripper2base[i] @ R_sample
                    AX_t = R_gripper2base[i] @ t_sample + t_gripper2base[i]

                    # XB
                    XB_R = R_sample @ R_target2cam[i]
                    XB_t = R_sample @ t_target2cam[i] + t_sample

                    # æ—‹è½¬è¯¯å·® (è½¬æ¢ä¸ºmmå½“é‡)
                    R_diff = AX_R @ XB_R.T
                    angle_error = np.arccos(np.clip((np.trace(R_diff) - 1) / 2, -1, 1))

                    # å¹³ç§»è¯¯å·® (mm)
                    t_error = np.linalg.norm(AX_t - XB_t) * 1000

                    # ç»¼åˆè¯¯å·®
                    total_error = t_error + np.degrees(angle_error) * 1.0
                    errors.append(total_error)

                errors_array = np.array(errors)

                # åŠ¨æ€é˜ˆå€¼
                median_error = np.median(errors_array)
                mad = np.median(np.abs(errors_array - median_error))
                dynamic_threshold = min(threshold, median_error + 2.5 * mad)

                # æ‰¾å‡ºå†…ç‚¹
                inliers = [i for i, e in enumerate(errors) if e < dynamic_threshold]

                min_inliers = max(4, int(n_samples * min_inlier_ratio))

                if len(inliers) >= min_inliers:
                    # ä½¿ç”¨å†…ç‚¹ç²¾åŒ–
                    R_refined, t_refined = cv2.calibrateHandEye(
                        [R_gripper2base[i] for i in inliers],
                        [t_gripper2base[i] for i in inliers],
                        [R_target2cam[i] for i in inliers],
                        [t_target2cam[i] for i in inliers],
                        method=cv2.CALIB_HAND_EYE_TSAI
                    )

                    # è®¡ç®—ç²¾åŒ–åçš„è¯¯å·®
                    refined_errors = []
                    for i in inliers:
                        AX_t = R_gripper2base[i] @ t_refined + t_gripper2base[i]
                        XB_t = R_refined @ t_target2cam[i] + t_refined
                        t_error = np.linalg.norm(AX_t - XB_t) * 1000
                        refined_errors.append(t_error)

                    median_error = np.median(refined_errors)

                    # é€‰æ‹©æœ€ä¼˜ç»“æœ
                    if len(inliers) > len(best_inliers) or \
                       (len(inliers) == len(best_inliers) and median_error < best_median_error):
                        best_inliers = inliers
                        best_median_error = median_error

            except:
                continue

        # å¦‚æœRANSACå¤±è´¥,ä½¿ç”¨ä¿å®ˆçš„è¯¯å·®è¿‡æ»¤
        if len(best_inliers) < max(4, int(n_samples * min_inlier_ratio)):
            print(f"   âš ï¸ RANSACå†…ç‚¹ä¸è¶³ï¼Œä½¿ç”¨ä¿å®ˆçš„è¯¯å·®é˜ˆå€¼è¿‡æ»¤")

            try:
                # ä½¿ç”¨æ‰€æœ‰æ•°æ®è®¡ç®—
                R_all, t_all = cv2.calibrateHandEye(
                    R_gripper2base, t_gripper2base,
                    R_target2cam, t_target2cam,
                    method=cv2.CALIB_HAND_EYE_TSAI
                )

                errors = []
                for i in range(n_samples):
                    AX_t = R_gripper2base[i] @ t_all + t_gripper2base[i]
                    XB_t = R_all @ t_target2cam[i] + t_all
                    t_error = np.linalg.norm(AX_t - XB_t) * 1000
                    errors.append(t_error)

                # ä½¿ç”¨ä¸­ä½æ•° + 3å€MAD
                median = np.median(errors)
                mad = np.median(np.abs(np.array(errors) - median))
                conservative_threshold = median + 3.0 * mad

                # ç»å¯¹ä¸Šé™15mm
                final_threshold = min(conservative_threshold, 15.0)

                best_inliers = [i for i, e in enumerate(errors) if e < final_threshold]

                # å¦‚æœè¿‡æ»¤å¤ªå¤š,ä¿ç•™æ‰€æœ‰
                if len(best_inliers) < int(n_samples * 0.8):
                    print(f"   â„¹ï¸  ä¿å®ˆè¿‡æ»¤ä»ä¼šç§»é™¤è¿‡å¤šæ•°æ®ï¼Œä¿ç•™æ‰€æœ‰å¸§")
                    best_inliers = list(range(n_samples))

            except:
                best_inliers = list(range(n_samples))

        return best_inliers

    @staticmethod
    def filter_reprojection_errors(collected_data, camera_matrix, dist_coeffs,
                                   board_size, chessboard_size_mm,
                                   max_error_px=2.0):
        """æ ¹æ®é‡æŠ•å½±è¯¯å·®è¿‡æ»¤å¸§

        Args:
            collected_data: é‡‡é›†æ•°æ®åˆ—è¡¨
            camera_matrix: ç›¸æœºå†…å‚çŸ©é˜µ
            dist_coeffs: ç•¸å˜ç³»æ•°
            board_size: æ£‹ç›˜æ ¼å°ºå¯¸ (cols, rows)
            chessboard_size_mm: æ–¹æ ¼å¤§å°(mm)
            max_error_px: æœ€å¤§é‡æŠ•å½±è¯¯å·®(åƒç´ )

        Returns:
            tuple: (filtered_data, removed_frames)
        """
        # å‡†å¤‡æ£‹ç›˜æ ¼ä¸–ç•Œåæ ‡
        square_size = chessboard_size_mm / 1000.0
        objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)
        objp[:, :2] = np.mgrid[0:board_size[0], 0:board_size[1]].T.reshape(-1, 2)
        objp *= square_size

        filtered = []
        removed = []

        for data in collected_data:
            ret, rvec, tvec = cv2.solvePnP(objp, data['corners'],
                                           camera_matrix, dist_coeffs)

            if ret:
                # è®¡ç®—é‡æŠ•å½±è¯¯å·®
                projected, _ = cv2.projectPoints(objp, rvec, tvec,
                                                camera_matrix, dist_coeffs)
                projected = projected.reshape(-1, 2)
                detected = data['corners'].reshape(-1, 2)
                error = np.sqrt(np.mean(np.sum((projected - detected)**2, axis=1)))

                if error < max_error_px:
                    filtered.append(data)
                else:
                    removed.append({
                        'frame_id': data['frame_id'],
                        'reprojection_error': error,
                        'reason': f'é‡æŠ•å½±è¯¯å·®{error:.2f}px>é˜ˆå€¼{max_error_px}px'
                    })
            else:
                removed.append({
                    'frame_id': data['frame_id'],
                    'reason': 'solvePnPå¤±è´¥'
                })

        return filtered, removed
