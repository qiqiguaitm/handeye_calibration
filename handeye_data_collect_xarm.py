# coding=utf-8
import math
from xarm.wrapper import XArmAPI
import json
import logging,os
import socket
import time
import sys
import numpy as np
import cv2
import pyrealsense2 as rs
from datetime import datetime
import yaml

from libs.log_setting import CommonLog
from libs.auxiliary import create_folder_with_date, get_ip, popup_message

# Camera intrinsics
from calibration_common import CameraIntrinsicsManager

# Global variables
data_path = None  # Will be created based on mode
calibration_mode = None  # 'eye_in_hand' or 'eye_to_hand'
collected_frames_data = []  # Store frame metadata
camera_serial = None  # RealSense camera serial number
tcp_offset = None  # TCP offset configuration [x, y, z, roll, pitch, yaw]

# Chessboard parameters - loaded from config
BOARD_SIZE = None  # Will be loaded from config
CHESSBOARD_SIZE_MM = None  # Will be loaded from config
CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
config_data = None  # Store loaded config

logger_ = logging.getLogger(__name__)
logger_ = CommonLog(logger_)

def load_config(mode=None):
    """Load calibration configuration from YAML file

    Args:
        mode: Calibration mode ('eye_in_hand' or 'eye_to_hand').
              If None, will try to load from global calibration_mode or config file.

    Returns:
        dict: Configuration data or None if failed
    """
    global BOARD_SIZE, CHESSBOARD_SIZE_MM, tcp_offset, config_data, calibration_mode

    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_file = os.path.join(script_dir, "config", "calibration_config_xarm.yaml")

    if not os.path.exists(config_file):
        logger_.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None

    try:
        with open(config_file, 'r') as f:
            config_data = yaml.load(f, Loader=yaml.FullLoader)

        # Determine which mode to use
        if mode is None:
            mode = calibration_mode  # Use global if set
        if mode is None:
            # Try to get from config file
            mode = config_data.get('calibration_mode', 'eye_in_hand')

        # Load chessboard parameters from mode-specific section
        if mode in config_data and 'chessboard' in config_data[mode]:
            # New structure: chessboard is under each mode
            BOARD_SIZE = tuple(config_data[mode]['chessboard']['board_size'])
            CHESSBOARD_SIZE_MM = config_data[mode]['chessboard']['square_size_mm']
            logger_.info(f"ä» {mode} é…ç½®ä¸­åŠ è½½æ£‹ç›˜æ ¼å‚æ•°")
        else:
            # Fallback: try old structure (top-level chessboard)
            if 'chessboard' in config_data:
                BOARD_SIZE = tuple(config_data['chessboard']['board_size'])
                CHESSBOARD_SIZE_MM = config_data['chessboard']['square_size_mm']
                logger_.warning(f"ä½¿ç”¨æ—§ç‰ˆé…ç½®ç»“æ„ï¼ˆé¡¶çº§ chessboardï¼‰")
            else:
                # Default values
                logger_.error(f"æœªæ‰¾åˆ° {mode} æ¨¡å¼çš„æ£‹ç›˜æ ¼é…ç½®")
                BOARD_SIZE = (6, 4)
                CHESSBOARD_SIZE_MM = 50.0

        # Load TCP offset if available
        if 'robot' in config_data and 'tcp_offset' in config_data['robot']:
            tcp_offset = config_data['robot']['tcp_offset']
            logger_.info(f"é…ç½®åŠ è½½æˆåŠŸ:")
            logger_.info(f"  - æ£‹ç›˜æ ¼å°ºå¯¸: {BOARD_SIZE}")
            logger_.info(f"  - æ–¹æ ¼å¤§å°: {CHESSBOARD_SIZE_MM}mm")
            logger_.info(f"  - TCPåç§»: {tcp_offset} (mm, mm, mm, deg, deg, deg)")
        else:
            tcp_offset = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
            logger_.info(f"é…ç½®åŠ è½½æˆåŠŸ:")
            logger_.info(f"  - æ£‹ç›˜æ ¼å°ºå¯¸: {BOARD_SIZE}")
            logger_.info(f"  - æ–¹æ ¼å¤§å°: {CHESSBOARD_SIZE_MM}mm")
            logger_.warning(f"  - æœªæ‰¾åˆ°TCPåç§»é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: [0, 0, 0, 0, 0, 0]")

        return config_data

    except Exception as e:
        logger_.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

def detect_chessboard(image):
    """Detect chessboard in image and refine corners

    Args:
        image: Color image (BGR format)

    Returns:
        tuple: (success, corners) where corners is refined corner positions
    """
    if image is None:
        return False, None

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Find chessboard corners with enhanced flags
    ret, corners = cv2.findChessboardCorners(
        gray, BOARD_SIZE,
        flags=cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FILTER_QUADS
    )

    if ret:
        # Refine corner positions to subpixel accuracy
        corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), CRITERIA)

    return ret, corners


def callback(frame, xarm):

    scaling_factor = 1.0
    global count, collected_frames_data

    # Keep original frame for saving
    original_frame = frame.copy()

    # Scale only for display
    cv_img = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)

    # Detect chessboard for real-time visualization (on scaled image)
    display_img = cv_img.copy()
    ret, corners = detect_chessboard(original_frame)

    if ret:
        # Draw chessboard corners
        cv2.drawChessboardCorners(display_img, BOARD_SIZE, corners, ret)
        cv2.putText(display_img, "Chessboard: DETECTED", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
    else:
        cv2.putText(display_img, "Chessboard: NOT DETECTED", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

    # Display collected count
    cv2.putText(display_img, f"Collected: {count-1}", (10, 70),
               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

    # Display instructions
    cv2.putText(display_img, "[S] Save  [ESC] Finish", (10, display_img.shape[0]-10),
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    cv2.imshow("Capture_Video", display_img)  # çª—å£æ˜¾ç¤ºï¼Œæ˜¾ç¤ºåä¸º Capture_Video

    k = cv2.waitKey(30) & 0xFF  # æ¯å¸§æ•°æ®å»¶æ—¶ 1msï¼Œå»¶æ—¶ä¸èƒ½ä¸º 0ï¼Œå¦åˆ™è¯»å–çš„ç»“æœä¼šæ˜¯é™æ€å¸§

    if k == ord('s'):  # è‹¥æ£€æµ‹åˆ°æŒ‰é”® 's'ï¼Œæ‰“å°å­—ç¬¦ä¸²
        state,pose = get_pos(xarm)
        logger_.info(f'è·å–çŠ¶æ€ï¼š{"æˆåŠŸ" if state else "å¤±è´¥"}ï¼Œ{f"å½“å‰ä½å§¿ä¸º{pose}" if state else None}')
        if state:
            # Save original image (not scaled) with new naming format: frame_id_Color.png
            image_path = os.path.join(data_path, f"{count}_Color.png")
            cv2.imwrite(image_path, original_frame)

            # Detect chessboard on the original image (not scaled)
            chessboard_ret, chessboard_corners = detect_chessboard(original_frame)

            if chessboard_ret:
                logger_.info(f"===é‡‡é›†ç¬¬{count}æ¬¡æ•°æ®ï¼æ£‹ç›˜æ ¼æ£€æµ‹æˆåŠŸ")
            else:
                logger_.info(f"===é‡‡é›†ç¬¬{count}æ¬¡æ•°æ®ï¼æ£‹ç›˜æ ¼æœªæ£€æµ‹åˆ°")

            # Store frame metadata (pose already in m and rad from get_pos)
            frame_data = {
                'frame_id': count,
                'pose': pose,  # [x, y, z, roll, pitch, yaw] in meters and radians
                'chessboard_detected': chessboard_ret
            }

            # Add corners if detected
            if chessboard_ret and chessboard_corners is not None:
                frame_data['corners'] = chessboard_corners.reshape(-1, 2).tolist()

            collected_frames_data.append(frame_data)

        count += 1

    elif k == 27:  # ESC key to finish
        return True  # Signal to stop collection

    return False  # Continue collection

def set_tcp_offset(xarm):
    """Set TCP offset to xArm robot

    Args:
        xarm: xArm robot client

    Returns:
        bool: True if successful, False otherwise
    """
    global tcp_offset

    if tcp_offset is None:
        logger_.warning("TCPåç§»æœªé…ç½®ï¼Œè·³è¿‡è®¾ç½®")
        return False

    try:
        # xArm API: set_tcp_offset(offset, is_radian=None, wait=True)
        # offset: list of 6 values [x, y, z, roll, pitch, yaw]
        # Units: mm, mm, mm, deg, deg, deg (when is_radian=False or None)
        # Note: wait=False to avoid blocking, set_tcp_offset doesn't need to wait
        code = xarm.set_tcp_offset(tcp_offset, is_radian=False, wait=False)

        if code != 0:
            logger_.error(f"è®¾ç½®TCPåç§»å¤±è´¥ï¼Œé”™è¯¯ç : {code}")
            return False

        # Give the robot time to apply the TCP offset
        time.sleep(0.5)

        logger_.info(f"âœ… TCPåç§»å·²è®¾ç½®: {tcp_offset}")

        # Verify the setting by reading the property
        current_offset = xarm.tcp_offset
        logger_.info(f"   å½“å‰TCPåç§»: {current_offset}")

        return True

    except Exception as e:
        logger_.error(f"è®¾ç½®TCPåç§»å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False


def get_pos(xarm):
    """Get robot arm position

    Returns:
        tuple: (success, pose) where pose is [x(m), y(m), z(m), roll(rad), pitch(rad), yaw(rad)]
    """
    code, pos = xarm.get_position()

    if code != 0:
        logger_.error(f"è·å–ä½å§¿å¤±è´¥ï¼Œé”™è¯¯ç : {code}")
        return False, None

    if not pos or len(pos) < 6:
        logger_.error(f"ä½å§¿æ•°æ®æ— æ•ˆ: {pos}")
        return False, None

    # Convert from xArm units (mm, degrees) to standard units (m, radians)
    x, y, z, roll, pitch, yaw = pos
    x = x / 1000.0  # mm -> m
    y = y / 1000.0  # mm -> m
    z = z / 1000.0  # mm -> m
    roll = roll * math.pi / 180.0  # deg -> rad
    pitch = pitch * math.pi / 180.0  # deg -> rad
    yaw = yaw * math.pi / 180.0  # deg -> rad

    return True, [x, y, z, roll, pitch, yaw]
#
def save_calibration_metadata():
    """Save all calibration metadata after collection completes"""
    global data_path, calibration_mode, collected_frames_data, camera_serial

    if not collected_frames_data:
        logger_.info("æ²¡æœ‰é‡‡é›†åˆ°æ•°æ®ï¼Œä¸ä¿å­˜å…ƒæ•°æ®")
        return

    # Save poses.txt in piper format
    poses_file = os.path.join(data_path, "poses.txt")
    with open(poses_file, 'w') as f:
        f.write("# Trajectory for replay - Robot arm end-effector poses\n")
        f.write("# Format: frame_id roll(rad) pitch(rad) yaw(rad) x(m) y(m) z(m)\n")
        timestamp = os.path.basename(data_path).replace('manual_calibration_eyeinhand_', '').replace('manual_calibration_eyetohand_', '')
        f.write(f"# Collection time: {timestamp}\n")
        f.write(f"# Collection mode: manual\n")
        f.write("#" + "-"*70 + "\n")
        for data in collected_frames_data:
            frame_id = data['frame_id']
            pose = data['pose']  # [x, y, z, roll, pitch, yaw] in meters and radians
            # Write in piper format: frame_id roll pitch yaw x y z
            f.write(f"{frame_id} {pose[3]:.6f} {pose[4]:.6f} {pose[5]:.6f} "
                   f"{pose[0]:.6f} {pose[1]:.6f} {pose[2]:.6f}\n")

    logger_.info(f"å·²ä¿å­˜ poses.txt: {len(collected_frames_data)} ä¸ªä½å§¿")

    # Save calibration_data.json
    data_file = os.path.join(data_path, "calibration_data.json")
    with open(data_file, 'w') as f:
        json.dump(collected_frames_data, f, indent=4)

    logger_.info(f"å·²ä¿å­˜ calibration_data.json: {len(collected_frames_data)} å¸§æ•°æ®")

    # Save calibration_metadata.json
    timestamp = os.path.basename(data_path).replace('manual_calibration_eyeinhand_', '').replace('manual_calibration_eyetohand_', '')
    metadata = {
        'calibration_mode': calibration_mode,
        'collection_mode': 'manual',
        'camera_id': camera_serial if camera_serial else 'unknown',
        'timestamp': timestamp,
        'version': '3.5.0'  # æ”¹è¿› replay æ¨¡å¼é”™è¯¯å¤„ç†å’Œè¿åŠ¨è§„åˆ’
    }

    metadata_file = os.path.join(data_path, "calibration_metadata.json")
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=4)

    logger_.info(f"å·²ä¿å­˜ calibration_metadata.json")
    logger_.info(f"  - ç›¸æœºID: {camera_serial if camera_serial else 'unknown'}")


def save_camera_intrinsics(pipeline):
    """Extract and save camera intrinsics to YAML file and get camera serial number"""
    global data_path, camera_serial

    try:
        profile = pipeline.get_active_profile()

        # Get camera serial number
        device = profile.get_device()
        camera_serial = device.get_info(rs.camera_info.serial_number)
        logger_.info(f"ğŸ“¹ ç›¸æœºåºåˆ—å·: {camera_serial}")

        color_stream = profile.get_stream(rs.stream.color)
        intrinsics = color_stream.as_video_stream_profile().get_intrinsics()

        camera_matrix = np.array([
            [intrinsics.fx, 0, intrinsics.ppx],
            [0, intrinsics.fy, intrinsics.ppy],
            [0, 0, 1]
        ], dtype=np.float32)

        dist_coeffs = np.array(intrinsics.coeffs[:5], dtype=np.float32)

        # Save to YAML file
        intrinsics_file = os.path.join(data_path, "realsense_intrinsics.yaml")
        CameraIntrinsicsManager.save_to_file(camera_matrix, dist_coeffs, intrinsics_file)

        logger_.info(f"å·²ä¿å­˜ç›¸æœºå†…å‚åˆ° realsense_intrinsics.yaml")
        logger_.info(f"  - fx={intrinsics.fx:.2f}, fy={intrinsics.fy:.2f}")
        logger_.info(f"  - cx={intrinsics.ppx:.2f}, cy={intrinsics.ppy:.2f}")

    except Exception as e:
        logger_.error(f"ä¿å­˜ç›¸æœºå†…å‚å¤±è´¥: {e}")
        camera_serial = None


def display_realsense(xarm, pipeline):
    """Display RealSense camera stream and collect calibration data

    Args:
        xarm: xArm robot client
        pipeline: RealSense pipeline (already started)
    """
    align_to = rs.stream.color
    align = rs.align(align_to)

    # Create resizable window
    cv2.namedWindow("Capture_Video", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Capture_Video", 1280, 720)  # Set initial size

    global count
    count = 1

    logger_.info(f"å¼€å§‹æ‰‹çœ¼æ ‡å®šç¨‹åºï¼Œå½“å‰ç¨‹åºç‰ˆå·V1.0.0")
    logger_.info(f"æ“ä½œè¯´æ˜ï¼š")
    logger_.info(f"  - æŒ‰ S é”®é‡‡é›†å½“å‰å¸§")
    logger_.info(f"  - æŒ‰ ESC é”®ç»“æŸé‡‡é›†")
    logger_.info(f"  - çª—å£æ”¯æŒé¼ æ ‡æ‹–æ‹½è°ƒæ•´å¤§å°")

    try:
        should_stop = False
        while not should_stop:
            frames = pipeline.wait_for_frames()
            frames = align.process(frames)
            color_frame = frames.get_color_frame()
            if not color_frame:
                continue

            color_image = np.asanyarray(color_frame.get_data())
            should_stop = callback(color_image, xarm)

    except KeyboardInterrupt:
        logger_.info("\nç”¨æˆ·ä¸­æ–­é‡‡é›†")

    finally:
        # Save all metadata before exiting
        save_calibration_metadata()

        cv2.destroyAllWindows()

        logger_.info(f"\næ•°æ®é‡‡é›†å®Œæˆï¼Œå…±é‡‡é›† {len(collected_frames_data)} å¸§")
        if collected_frames_data:
            chessboard_count = sum(1 for d in collected_frames_data if d.get('chessboard_detected', False))
            logger_.info(f"  - æˆåŠŸæ£€æµ‹åˆ°æ£‹ç›˜æ ¼: {chessboard_count}/{len(collected_frames_data)} å¸§")
            logger_.info(f"  - æ•°æ®ä¿å­˜è·¯å¾„: {data_path}")


def load_trajectory(trajectory_file):
    """Load trajectory from poses.txt file

    Args:
        trajectory_file: Path to poses.txt

    Returns:
        list: List of poses [x, y, z, roll, pitch, yaw] in meters and radians
    """
    if not os.path.exists(trajectory_file):
        logger_.error(f"è½¨è¿¹æ–‡ä»¶ä¸å­˜åœ¨: {trajectory_file}")
        return []

    poses = []

    try:
        with open(trajectory_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue

                # Format: frame_id roll(rad) pitch(rad) yaw(rad) x(m) y(m) z(m)
                parts = line.split()

                if len(parts) != 7:
                    logger_.warning(f"æ— æ•ˆçš„è¡Œæ ¼å¼ (æœŸæœ›7ä¸ªå­—æ®µ): {line}")
                    continue

                frame_id = int(parts[0])
                roll_rad = float(parts[1])
                pitch_rad = float(parts[2])
                yaw_rad = float(parts[3])
                x_m = float(parts[4])
                y_m = float(parts[5])
                z_m = float(parts[6])

                # Return as [x, y, z, roll, pitch, yaw]
                pose = [x_m, y_m, z_m, roll_rad, pitch_rad, yaw_rad]
                poses.append(pose)

        if not poses:
            logger_.error("è½¨è¿¹æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä½å§¿")

        return poses

    except Exception as e:
        logger_.error(f"åŠ è½½è½¨è¿¹æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def replay_trajectory(xarm, pipeline, trajectory_file, data_path):
    """Replay trajectory and collect calibration data

    Args:
        xarm: xArm robot client
        pipeline: RealSense pipeline
        trajectory_file: Path to trajectory file (poses.txt)
        data_path: Directory to save collected data
    """
    logger_.info("\n" + "="*60)
    logger_.info("é‡æ”¾è½¨è¿¹é‡‡é›†æ¨¡å¼")
    logger_.info("="*60)

    # Load trajectory
    poses = load_trajectory(trajectory_file)
    if not poses:
        logger_.error("åŠ è½½è½¨è¿¹å¤±è´¥")
        return

    logger_.info(f"ä»è½¨è¿¹æ–‡ä»¶åŠ è½½äº† {len(poses)} ä¸ªä½å§¿")

    # Create resizable window
    cv2.namedWindow("Replay_Mode", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Replay_Mode", 1280, 720)

    global collected_frames_data
    collected_frames_data = []

    # Motion config
    stability_wait = 3.0  # seconds to wait for stability (increased for better settling)
    capture_speed = 20  # movement speed (slower for better accuracy)

    # Configure robot for safer motion planning
    #logger_.info("é…ç½®æœºæ¢°è‡‚è¿åŠ¨å‚æ•°...")
    #xarm.set_tcp_jerk(1000)  # é™ä½åŠ åŠ é€Ÿåº¦ï¼Œä½¿è¿åŠ¨æ›´å¹³æ»‘
    #xarm.set_tcp_maxacc(500)  # é™ä½æœ€å¤§åŠ é€Ÿåº¦
    #logger_.info("è¿åŠ¨å‚æ•°é…ç½®å®Œæˆ")

    # Check and clear any existing errors before starting
    logger_.info("\næ£€æŸ¥å¹¶æ¸…ç†æœºæ¢°è‡‚çŠ¶æ€...")
    xarm.clean_error()
    xarm.clean_warn()
    time.sleep(0.5)

    # Get and display current state
    code, state = xarm.get_state()
    logger_.info(f"å½“å‰çŠ¶æ€ç : {state}")

    # Ensure robot is in motion state
    if state != 0:
        logger_.info("é‡æ–°è®¾ç½®æœºæ¢°è‡‚ä¸ºè¿åŠ¨çŠ¶æ€...")
        xarm.set_mode(0)
        xarm.set_state(0)
        time.sleep(0.5)

    try:
        for idx, pose_data in enumerate(poses):
            logger_.info(f"\n[{idx+1}/{len(poses)}] ç§»åŠ¨åˆ°ä½å§¿...")

            # Unpack pose (in meters and radians from file)
            x_m, y_m, z_m, roll_rad, pitch_rad, yaw_rad = pose_data

            # Convert to mm and degrees (xArm API units)
            x_mm = x_m * 1000.0
            y_mm = y_m * 1000.0
            z_mm = z_m * 1000.0
            roll_deg = np.degrees(roll_rad)
            pitch_deg = np.degrees(pitch_rad)
            yaw_deg = np.degrees(yaw_rad)

            logger_.info(f"  ç›®æ ‡: X={x_mm:.1f}mm Y={y_mm:.1f}mm Z={z_mm:.1f}mm")
            logger_.info(f"        Roll={roll_deg:.1f}Â° Pitch={pitch_deg:.1f}Â° Yaw={yaw_deg:.1f}Â°")

            # Move to target pose
            # Try motion_type=1 first (linear with fallback), then motion_type=2 (pure joint) if fails
            code = xarm.set_position(
                x=x_mm, y=y_mm, z=z_mm,
                roll=roll_deg, pitch=pitch_deg, yaw=yaw_deg,
                wait=True, speed=capture_speed,
                motion_type=0
            )
            
            if code != 0:
                logger_.warning(f"  ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®å¤±è´¥ï¼Œé”™è¯¯ç : {code}")
                if code == 9:
                    logger_.warning(f"  é”™è¯¯åŸå› : ç›®æ ‡ä½ç½®è¶…å‡ºå·¥ä½œç©ºé—´èŒƒå›´")
                    logger_.warning(f"  é—®é¢˜ä½ç½®: X={x_mm:.1f} Y={y_mm:.1f} Z={z_mm:.1f}")
                    logger_.warning(f"  å§¿æ€è§’åº¦: Roll={roll_deg:.1f}Â° Pitch={pitch_deg:.1f}Â° Yaw={yaw_deg:.1f}Â°")

                logger_.info(f"  æ¸…ç†æœºæ¢°è‡‚é”™è¯¯çŠ¶æ€...")
                xarm.clean_error()
                xarm.clean_warn()
                time.sleep(0.5)

                # Re-enable motion (error may put robot in stop state)
                logger_.info(f"  é‡æ–°æ¿€æ´»æœºæ¢°è‡‚è¿åŠ¨çŠ¶æ€...")
                xarm.set_mode(0)  # Position control mode
                xarm.set_state(0)  # Sport state
                time.sleep(0.5)

                logger_.info(f"  è·³è¿‡å½“å‰poseï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ª")
                continue

            # Wait for stability
            logger_.info(f"  ç­‰å¾… {stability_wait}s ä»¥ç¡®ä¿ç¨³å®š...")
            time.sleep(stability_wait)

            # Get actual position
            success, actual_pose = get_pos(xarm)
            if not success:
                logger_.warning("  æ— æ³•è·å–å®é™…ä½ç½®")
                logger_.info(f"  æ¸…ç†æœºæ¢°è‡‚é”™è¯¯çŠ¶æ€...")
                xarm.clean_error()
                xarm.clean_warn()
                time.sleep(0.5)

                # Re-enable motion (error may put robot in stop state)
                logger_.info(f"  é‡æ–°æ¿€æ´»æœºæ¢°è‡‚è¿åŠ¨çŠ¶æ€...")
                xarm.set_mode(0)  # Position control mode
                xarm.set_state(0)  # Sport state
                time.sleep(0.5)

                logger_.info(f"  è·³è¿‡å½“å‰poseï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ª")
                continue

            # Check position error (convert actual_pose from m to mm for comparison)
            pos_error = [
                abs(actual_pose[0] * 1000.0 - x_mm),
                abs(actual_pose[1] * 1000.0 - y_mm),
                abs(actual_pose[2] * 1000.0 - z_mm)
            ]
            max_error = max(pos_error)

            if max_error > 2.0:
                logger_.warning(f"  ä½ç½®è¯¯å·® {max_error:.2f}mm > 2mm")
            else:
                logger_.info(f"  åˆ°è¾¾ç›®æ ‡ä½ç½® (è¯¯å·® < 2mm)")

            # Capture image from camera - flush buffer to get latest frame
            logger_.info("  æ¸…ç©ºç›¸æœºç¼“å†²åŒºï¼Œè·å–æœ€æ–°å¸§...")
            for _ in range(5):  # Discard old frames from buffer
                pipeline.wait_for_frames()

            frames = pipeline.wait_for_frames()  # Get fresh frame
            color_frame = frames.get_color_frame()
            if not color_frame:
                logger_.warning("  æ— æ³•è·å–å›¾åƒå¸§")
                continue

            original_frame = np.asanyarray(color_frame.get_data())

            # Scale for display
            scaling_factor = 1.0
            display_img = cv2.resize(original_frame, None, fx=scaling_factor, fy=scaling_factor,
                                    interpolation=cv2.INTER_AREA)

            # Detect chessboard on original image
            chessboard_ret, chessboard_corners = detect_chessboard(original_frame)

            # Draw on display image (scaled)
            if chessboard_ret:
                # Scale corners for display
                corners_scaled = chessboard_corners * scaling_factor
                cv2.drawChessboardCorners(display_img, BOARD_SIZE, corners_scaled, True)
                cv2.putText(display_img, "DETECTED", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
            else:
                cv2.putText(display_img, "NOT DETECTED", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

            # Display progress
            cv2.putText(display_img, f"Replay: {idx+1}/{len(poses)}", (10, 70),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
            cv2.putText(display_img, "[ESC] Stop", (10, display_img.shape[0]-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            cv2.imshow("Replay_Mode", display_img)
            key = cv2.waitKey(1) & 0xFF

            if key == 27:  # ESC
                logger_.info("\nç”¨æˆ·ä¸­æ–­é‡‡é›†")
                break

            # Save image (original, not scaled)
            frame_id = idx + 1
            image_path = os.path.join(data_path, f"{frame_id}_Color.png")
            cv2.imwrite(image_path, original_frame)

            # actual_pose is already in meters and radians from get_pos()
            # No need to convert again

            # Store metadata
            frame_data = {
                'frame_id': frame_id,
                'pose': actual_pose,  # Already in m and rad
                'chessboard_detected': chessboard_ret
            }

            if chessboard_ret and chessboard_corners is not None:
                frame_data['corners'] = chessboard_corners.reshape(-1, 2).tolist()

            collected_frames_data.append(frame_data)

            if chessboard_ret:
                logger_.info(f"  âœ… å·²é‡‡é›†ç¬¬ {frame_id} å¸§æ•°æ® (æ£‹ç›˜æ ¼æ£€æµ‹æˆåŠŸ)")
            else:
                logger_.info(f"  âš ï¸  å·²é‡‡é›†ç¬¬ {frame_id} å¸§æ•°æ® (æ£‹ç›˜æ ¼æœªæ£€æµ‹åˆ°)")

        cv2.destroyAllWindows()

        # Save metadata
        save_calibration_metadata()

        logger_.info(f"\næ•°æ®é‡‡é›†å®Œæˆï¼Œå…±é‡‡é›† {len(collected_frames_data)} å¸§")
        if collected_frames_data:
            chessboard_count = sum(1 for d in collected_frames_data if d.get('chessboard_detected', False))
            logger_.info(f"  - æˆåŠŸæ£€æµ‹åˆ°æ£‹ç›˜æ ¼: {chessboard_count}/{len(collected_frames_data)} å¸§")
            logger_.info(f"  - æ•°æ®ä¿å­˜è·¯å¾„: {data_path}")

    except KeyboardInterrupt:
        logger_.info("\nç”¨æˆ·ä¸­æ–­é‡‡é›†")
        cv2.destroyAllWindows()
    except Exception as e:
        logger_.error(f"é‡æ”¾è½¨è¿¹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        cv2.destroyAllWindows()


if __name__ == '__main__':

    print("="*60)
    print("Hand-Eye Calibration Data Collector for xArm v3.4.1")
    print("="*60)

    # Load configuration first
    if load_config() is None:
        print("é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
        sys.exit(1)

    # é€‰æ‹©é‡‡é›†æ¨¡å¼
    print("\né‡‡é›†æ¨¡å¼:")
    print("  1. Manual (æ‰‹åŠ¨é‡‡é›†)")
    print("  2. Replay (é‡æ”¾è½¨è¿¹)")
    collection_mode = input("é€‰æ‹©é‡‡é›†æ¨¡å¼ (1/2) [é»˜è®¤ 1]: ").strip()

    # é€‰æ‹©æ ‡å®šæ¨¡å¼
    print("\næ ‡å®šæ¨¡å¼:")
    print("  1. Eye-in-Hand (ç›¸æœºåœ¨æœ«ç«¯ï¼Œæ£‹ç›˜æ ¼å›ºå®š)")
    print("  2. Eye-to-Hand (ç›¸æœºå›ºå®šï¼Œæ£‹ç›˜æ ¼åœ¨æœ«ç«¯)")
    mode_choice = input("é€‰æ‹©æ ‡å®šæ¨¡å¼ (1/2) [é»˜è®¤ 1]: ").strip()

    if mode_choice == "2":
        calibration_mode = "eye_to_hand"
        print("\nğŸ“· æ¨¡å¼: Eye-to-Hand")
        print("   - ç›¸æœºå›ºå®šåœ¨åŸºåº§é™„è¿‘")
        print("   - æ£‹ç›˜æ ¼å›ºå®šåœ¨æœºæ¢°è‡‚æœ«ç«¯")
    else:
        calibration_mode = "eye_in_hand"
        print("\nğŸ“· æ¨¡å¼: Eye-in-Hand")
        print("   - ç›¸æœºå›ºå®šåœ¨æœºæ¢°è‡‚æœ«ç«¯")
        print("   - æ£‹ç›˜æ ¼å›ºå®šåœ¨å¤–éƒ¨")

    # Reload configuration with selected mode to get correct chessboard parameters
    if load_config(calibration_mode) is None:
        print("é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
        sys.exit(1)

    print("="*60)

    # Create calibration data directory with mode suffix
    script_dir = os.path.dirname(os.path.abspath(__file__))
    calibration_data_base = os.path.join(script_dir, "calibration_data")
    os.makedirs(calibration_data_base, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    calibration_mode_short = calibration_mode.replace('_', '')  # eyeinhand / eyetohand

    # Determine collection mode prefix
    if collection_mode == "2":
        mode_prefix = "replay_calibration"
    else:
        mode_prefix = "manual_calibration"

    data_path = os.path.join(
        calibration_data_base,
        f"{mode_prefix}_{calibration_mode_short}_{timestamp}"
    )
    os.makedirs(data_path, exist_ok=True)

    logger_.info(f"æ•°æ®å°†ä¿å­˜åˆ°: {data_path}")

    # xArm connection
    xarm_ip = '192.168.1.236'
    logger_.info(f'xarm_ip: {xarm_ip}')

    try:
        xarm = XArmAPI(xarm_ip)
        logger_.info("æœºæ¢°è‡‚è¿æ¥æˆåŠŸ")

        # Enable motion
        code = xarm.motion_enable(enable=True)
        if code != 0:
            logger_.error(f"ä½¿èƒ½æœºæ¢°è‡‚å¤±è´¥ï¼Œé”™è¯¯ç : {code}")
            popup_message("é”™è¯¯", f"ä½¿èƒ½æœºæ¢°è‡‚å¤±è´¥ï¼Œé”™è¯¯ç : {code}")
            sys.exit(1)
        logger_.info("æœºæ¢°è‡‚å·²ä½¿èƒ½")

        # Set mode: 0=position control, 1=servo motion, 2=joint teaching
        code = xarm.set_mode(0)  # Position control mode
        if code != 0:
            logger_.warning(f"è®¾ç½®æ¨¡å¼å¤±è´¥ï¼Œé”™è¯¯ç : {code}")

        # Set state: 0=sport, 3=pause, 4=stop
        code = xarm.set_state(0)  # Sport state
        if code != 0:
            logger_.warning(f"è®¾ç½®çŠ¶æ€å¤±è´¥ï¼Œé”™è¯¯ç : {code}")

        logger_.info("æœºæ¢°è‡‚åˆå§‹åŒ–å®Œæˆ")

        

        # Re-enable motion after TCP offset (setting TCP may change robot state)
        logger_.info("\né‡æ–°ç¡®è®¤æœºæ¢°è‡‚çŠ¶æ€...")
        code = xarm.set_mode(0)  # Position control mode
        if code != 0:
            logger_.warning(f"é‡æ–°è®¾ç½®æ¨¡å¼å¤±è´¥ï¼Œé”™è¯¯ç : {code}")

        code = xarm.set_state(0)  # Sport state
        if code != 0:
            logger_.warning(f"é‡æ–°è®¾ç½®çŠ¶æ€å¤±è´¥ï¼Œé”™è¯¯ç : {code}")

        # Set TCP offset if configured
        logger_.info("\n" + "="*60)
        logger_.info("è®¾ç½®TCPåç§»")
        logger_.info("="*60)
        set_tcp_offset(xarm)
        
        logger_.info("âœ… æœºæ¢°è‡‚å‡†å¤‡å°±ç»ª")

    except Exception as e:
        logger_.error(f"æœºæ¢°è‡‚è¿æ¥å¤±è´¥: {e}")
        popup_message("é”™è¯¯", f"æœºæ¢°è‡‚è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)

    # Initialize camera
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
    config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)

    try:
        pipeline.start(config)
    except Exception as e:
        logger_.error(f"ç›¸æœºè¿æ¥å¼‚å¸¸ï¼š{e}")
        popup_message("æé†’", "ç›¸æœºè¿æ¥å¼‚å¸¸")
        sys.exit(1)

    # Save camera intrinsics
    save_camera_intrinsics(pipeline)

    # Choose collection mode
    if collection_mode == "2":
        # Replay mode
        print("\n" + "="*60)
        print("é‡æ”¾æ¨¡å¼ - é€‰æ‹©è½¨è¿¹æ–‡ä»¶")
        print("="*60)

        # List available trajectory files
        available_trajectories = []
        for item in os.listdir(calibration_data_base):
            item_path = os.path.join(calibration_data_base, item)
            if os.path.isdir(item_path):
                poses_file = os.path.join(item_path, "poses.txt")
                if os.path.exists(poses_file):
                    available_trajectories.append((item, poses_file))

        if not available_trajectories:
            print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è½¨è¿¹æ–‡ä»¶")
            print("è¯·å…ˆä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼é‡‡é›†æ•°æ®")
            sys.exit(1)

        print("\nå¯ç”¨çš„è½¨è¿¹æ–‡ä»¶:")
        for idx, (dirname, filepath) in enumerate(available_trajectories, 1):
            print(f"  {idx}. {dirname}")

        traj_choice = input(f"\né€‰æ‹©è½¨è¿¹ (1-{len(available_trajectories)}): ").strip()
        try:
            traj_idx = int(traj_choice) - 1
            if 0 <= traj_idx < len(available_trajectories):
                selected_trajectory = available_trajectories[traj_idx][1]
                print(f"å·²é€‰æ‹©: {available_trajectories[traj_idx][0]}")
            else:
                print("æ— æ•ˆé€‰æ‹©")
                sys.exit(1)
        except ValueError:
            print("æ— æ•ˆè¾“å…¥")
            sys.exit(1)

        # Start replay
        replay_trajectory(xarm, pipeline, selected_trajectory, data_path)

    else:
        # Manual mode
        display_realsense(xarm, pipeline)

    # Cleanup
    pipeline.stop()
