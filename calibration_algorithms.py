#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
calibration_algorithms.py - æ‰‹çœ¼æ ‡å®šç®—æ³•æ¨¡å—

æä¾›:
- å¤šç®—æ³•èåˆ (Tsai, Park, Horaud, Daniilidis, Andreff)
- è¿­ä»£éçº¿æ€§ä¼˜åŒ–
- æ ‡å®šç»“æœè¯„ä¼°
- è¯¯å·®åˆ†æ

Design: Linus "Good Taste" åŸåˆ™
- æ¯ä¸ªç®—æ³•ç‹¬ç«‹,å¯å•ç‹¬æµ‹è¯•
- å¤±è´¥æ—¶ä¼˜é›…é™çº§
- æ¸…æ™°çš„è¯¯å·®åº¦é‡
"""

import numpy as np
import cv2
from scipy.optimize import minimize
from scipy.spatial.transform import Rotation as R


# ============================================================================
# æ‰‹çœ¼æ ‡å®šç®—æ³•
# ============================================================================

class HandEyeCalibration:
    """æ‰‹çœ¼æ ‡å®šç®—æ³•é›†åˆ"""

    @staticmethod
    def invert_transformations(R_list, t_list):
        """å¯¹å˜æ¢åˆ—è¡¨æ±‚é€†: T^(-1) = [R^T | -R^T*t]

        ç”¨äº eye-to-hand: å°† gripper2base è½¬æ¢ä¸º base2gripper

        Args:
            R_list: æ—‹è½¬çŸ©é˜µåˆ—è¡¨
            t_list: å¹³ç§»å‘é‡åˆ—è¡¨

        Returns:
            (R_inv_list, t_inv_list): é€†å˜æ¢åˆ—è¡¨
        """
        R_inv_list = []
        t_inv_list = []

        for R, t in zip(R_list, t_list):
            # T^(-1) = [R^T | -R^T * t]
            R_inv = R.T
            t_inv = -R_inv @ t

            R_inv_list.append(R_inv)
            t_inv_list.append(t_inv)

        return R_inv_list, t_inv_list

    @staticmethod
    def multi_algorithm_fusion(R_gripper2base, t_gripper2base,
                               R_target2cam, t_target2cam, verbose=True):
        """å¤šç®—æ³•èåˆ - é€‰æ‹©æœ€ä½³ç®—æ³•

        æµ‹è¯•5ç§ç»å…¸æ‰‹çœ¼æ ‡å®šç®—æ³•,é€‰æ‹©ä½å§¿é‡å¤æ€§æœ€å¥½çš„

        Args:
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_cam2gripper, t_cam2gripper, method_name) æˆ– (None, None, None)
        """
        methods = [
            (cv2.CALIB_HAND_EYE_TSAI, "Tsai"),
            (cv2.CALIB_HAND_EYE_PARK, "Park"),
            (cv2.CALIB_HAND_EYE_HORAUD, "Horaud"),
            (cv2.CALIB_HAND_EYE_DANIILIDIS, "Daniilidis"),
            (cv2.CALIB_HAND_EYE_ANDREFF, "Andreff")
        ]

        best_result = None
        best_score = float('inf')
        best_method = None

        for method_id, method_name in methods:
            try:
                R_test, t_test = cv2.calibrateHandEye(
                    R_gripper2base, t_gripper2base,
                    R_target2cam, t_target2cam,
                    method=method_id
                )

                # è¯„ä¼°æ ‡å®šè´¨é‡: ä½å§¿é‡å¤æ€§
                t_errors = []
                r_errors = []

                # è®¡ç®—æ¯å¸§ä¸‹targetåœ¨baseåæ ‡ç³»çš„ä½å§¿
                for i in range(len(R_gripper2base)):
                    R_pred = R_gripper2base[i] @ R_test @ R_target2cam[i]
                    t_pred = R_gripper2base[i] @ (R_test @ t_target2cam[i] + t_test) + t_gripper2base[i]

                    if i == 0:
                        R_ref = R_pred
                        t_ref = t_pred
                    else:
                        # å¹³ç§»è¯¯å·® (mm)
                        t_error = np.linalg.norm(t_pred - t_ref) * 1000
                        t_errors.append(t_error)

                        # æ—‹è½¬è¯¯å·® (åº¦)
                        R_error = R_ref.T @ R_pred
                        r_error = np.degrees(np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1)))
                        r_errors.append(r_error)

                avg_t_error = np.mean(t_errors) if t_errors else 0
                avg_r_error = np.mean(r_errors) if r_errors else 0

                # ç»¼åˆè¯„åˆ†: å½’ä¸€åŒ–ååŠ æƒæ±‚å’Œ
                # å¹³ç§»: 5mm = 1.0, æ—‹è½¬: 0.5Â° = 1.0
                score = (avg_t_error / 5.0) + (avg_r_error / 0.5)

                if verbose:
                    print(f"   {method_name}: å¹³ç§»={avg_t_error:.3f}mm, æ—‹è½¬={avg_r_error:.3f}Â°, ç»¼åˆ={score:.3f}")

                if score < best_score:
                    best_score = score
                    best_result = (R_test, t_test)
                    best_method = method_name

            except Exception as e:
                if verbose:
                    print(f"   {method_name}: å¤±è´¥ ({e})")

        if best_result:
            return best_result[0], best_result[1], best_method

        return None, None, None

    @staticmethod
    def multi_algorithm_fusion_with_mode(R_gripper2base, t_gripper2base,
                                          R_target2cam, t_target2cam,
                                          mode='eye_in_hand', verbose=True):
        """å¤šç®—æ³•èåˆ - æ”¯æŒ eye-in-hand å’Œ eye-to-hand

        Args:
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            mode: 'eye_in_hand' æˆ– 'eye_to_hand'
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_result, t_result, method_name) æˆ– (None, None, None)
        """
        if verbose:
            if mode == 'eye_in_hand':
                print(f"  æ ‡å®šæ¨¡å¼: Eye-in-Hand (ç›¸æœºåœ¨æœ«ç«¯)")
                print(f"  æ±‚è§£: camera_to_gripper")
            else:
                print(f"  æ ‡å®šæ¨¡å¼: Eye-to-Hand (ç›¸æœºå›ºå®š)")
                print(f"  æ±‚è§£: camera_to_base")

        # Eye-to-hand: éœ€è¦å¯¹æœºå™¨äººä½å§¿æ±‚é€†
        if mode == 'eye_to_hand':
            if verbose:
                print("  è½¬æ¢: gripper2base â†’ base2gripper")
            R_A, t_A = HandEyeCalibration.invert_transformations(
                R_gripper2base, t_gripper2base
            )
        else:
            # Eye-in-hand: ç›´æ¥ä½¿ç”¨
            R_A, t_A = R_gripper2base, t_gripper2base

        # ä½¿ç”¨ç»Ÿä¸€çš„ç®—æ³•ï¼ˆå®Œå…¨å¤ç”¨ç°æœ‰ä»£ç ï¼‰
        R_result, t_result, method_name = HandEyeCalibration.multi_algorithm_fusion(
            R_A, t_A, R_target2cam, t_target2cam, verbose=verbose
        )

        return R_result, t_result, method_name

    @staticmethod
    def iterative_optimization(R_initial, t_initial, R_gripper2base,
                              t_gripper2base, R_target2cam, t_target2cam,
                              verbose=True):
        """è¿­ä»£éçº¿æ€§ä¼˜åŒ–

        ä½¿ç”¨L-BFGS-Bä¼˜åŒ–å™¨å¾®è°ƒæ ‡å®šç»“æœ,æœ€å°åŒ–ä½å§¿é‡å¤æ€§è¯¯å·®

        Args:
            R_initial: åˆå§‹æ—‹è½¬çŸ©é˜µ
            t_initial: åˆå§‹å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_optimized, t_optimized)
        """

        def objective(params):
            """ç›®æ ‡å‡½æ•°: æœ€å°åŒ–ä½å§¿é‡å¤æ€§è¯¯å·®"""
            # è§£æå‚æ•°
            rvec = params[:3]
            tvec = params[3:6]

            # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
            R_opt, _ = cv2.Rodrigues(rvec)
            t_opt = tvec.reshape(3, 1)

            # è®¡ç®—æ¯å¸§ä¸‹targetåœ¨baseåæ ‡ç³»çš„ä½å§¿
            R_preds = []
            t_preds = []

            for i in range(len(R_gripper2base)):
                R_pred = R_gripper2base[i] @ R_opt @ R_target2cam[i]
                t_pred = R_gripper2base[i] @ (R_opt @ t_target2cam[i] + t_opt) + t_gripper2base[i]
                R_preds.append(R_pred)
                t_preds.append(t_pred)

            # ä»¥ç¬¬ä¸€å¸§ä¸ºå‚è€ƒ,è®¡ç®—æ‰€æœ‰å¸§çš„åå·®
            R_ref = R_preds[0]
            t_ref = t_preds[0]

            total_error = 0
            for i in range(1, len(R_preds)):
                # æ—‹è½¬è¯¯å·® (åº¦)
                R_error = R_ref.T @ R_preds[i]
                angle_error = np.degrees(np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1)))

                # å¹³ç§»è¯¯å·® (mm)
                t_error = np.linalg.norm(t_preds[i] - t_ref) * 1000

                # ç»¼åˆè¯¯å·® (1Â° = 10mm)
                total_error += t_error * 0.8   + angle_error * 10.0  * 0.2

            return total_error

        # åˆå§‹å‚æ•°
        rvec_init, _ = cv2.Rodrigues(R_initial)
        tvec_init = t_initial.flatten()
        params_init = np.concatenate([rvec_init.flatten(), tvec_init])

        # è®¡ç®—åˆå§‹è¯¯å·®
        error_before = objective(params_init)

        # è®¾ç½®è¾¹ç•Œ: å…è®¸å¾®è°ƒ (Â±5Â°, Â±10mm)
        bounds = []
        for i in range(3):
            # æ—‹è½¬: Â±5Â° â‰ˆ Â±0.087 rad
            bounds.append((rvec_init[i] - 0.087, rvec_init[i] + 0.087))
        for i in range(3):
            # å¹³ç§»: Â±10mm = Â±0.01m
            bounds.append((tvec_init[i] - 0.01, tvec_init[i] + 0.01))

        # L-BFGS-Bä¼˜åŒ–
        result = minimize(
            objective,
            params_init,
            method='L-BFGS-B',
            bounds=bounds,
            options={
                'maxiter': 50,
                'ftol': 1e-6,
                'gtol': 1e-5
            }
        )

        # è§£æç»“æœ
        rvec_opt = result.x[:3]
        tvec_opt = result.x[3:6]
        R_opt, _ = cv2.Rodrigues(rvec_opt)
        t_opt = tvec_opt.reshape(3, 1)

        # è®¡ç®—ä¼˜åŒ–åè¯¯å·®
        error_after = objective(result.x)

        # å¦‚æœä¼˜åŒ–åæ›´å·®,é€€å›åˆå§‹å€¼
        if error_after > error_before:
            if verbose:
                print(f"   âš ï¸  ä¼˜åŒ–æœªæ”¹å–„ç»“æœï¼Œä½¿ç”¨åˆå§‹å€¼")
                print(f"   ä¼˜åŒ–å‰: {error_before:.3f}, ä¼˜åŒ–å: {error_after:.3f}")
            return R_initial, t_initial
        else:
            improvement = (error_before - error_after) / error_before * 100
            if verbose:
                print(f"   âœ… ä¼˜åŒ–æˆåŠŸ: {error_before:.3f} â†’ {error_after:.3f} (æ”¹å–„{improvement:.1f}%)")
            return R_opt, t_opt

    @staticmethod
    def iterative_optimization_with_mode(R_initial, t_initial, R_gripper2base,
                                          t_gripper2base, R_target2cam, t_target2cam,
                                          mode='eye_in_hand', verbose=True):
        """è¿­ä»£éçº¿æ€§ä¼˜åŒ– - æ”¯æŒä¸¤ç§æ¨¡å¼

        Args:
            R_initial: åˆå§‹æ—‹è½¬çŸ©é˜µ
            t_initial: åˆå§‹å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            mode: 'eye_in_hand' æˆ– 'eye_to_hand'
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_optimized, t_optimized)
        """
        # Eye-to-hand: è½¬æ¢åæ ‡
        if mode == 'eye_to_hand':
            R_A, t_A = HandEyeCalibration.invert_transformations(
                R_gripper2base, t_gripper2base
            )
        else:
            R_A, t_A = R_gripper2base, t_gripper2base

        # å¤ç”¨ç°æœ‰ä¼˜åŒ–ç®—æ³•
        return HandEyeCalibration.iterative_optimization(
            R_initial, t_initial, R_A, t_A,
            R_target2cam, t_target2cam, verbose=verbose
        )

    @staticmethod
    def levenberg_marquardt_optimization(R_initial, t_initial, R_gripper2base,
                                         t_gripper2base, R_target2cam, t_target2cam,
                                         verbose=True):
        """Levenberg-Marquardt éçº¿æ€§ä¼˜åŒ–

        ä½¿ç”¨ LM ç®—æ³•ä¼˜åŒ–æ ‡å®šç»“æœï¼Œæœ€å°åŒ–ä½å§¿é‡å¤æ€§æ®‹å·®

        Args:
            R_initial: åˆå§‹æ—‹è½¬çŸ©é˜µ
            t_initial: åˆå§‹å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_optimized, t_optimized)
        """
        from scipy.optimize import least_squares

        def residual_function(params):
            """æ®‹å·®å‡½æ•°: è®¡ç®—æ‰€æœ‰å¸§çš„ä½å§¿åå·®

            è¿”å›æ®‹å·®å‘é‡ï¼ŒLM ä¼šæœ€å°åŒ– sum(residuals^2)
            """
            # è§£æå‚æ•°
            rvec = params[:3]
            tvec = params[3:6]

            # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
            R_opt, _ = cv2.Rodrigues(rvec)
            t_opt = tvec.reshape(3, 1)

            # è®¡ç®—æ¯å¸§ä¸‹ target åœ¨ base åæ ‡ç³»çš„ä½å§¿
            R_preds = []
            t_preds = []

            for i in range(len(R_gripper2base)):
                R_pred = R_gripper2base[i] @ R_opt @ R_target2cam[i]
                t_pred = R_gripper2base[i] @ (R_opt @ t_target2cam[i] + t_opt) + t_gripper2base[i]
                R_preds.append(R_pred)
                t_preds.append(t_pred)

            # ä»¥ç¬¬ä¸€å¸§ä¸ºå‚è€ƒï¼Œè®¡ç®—æ‰€æœ‰å¸§çš„æ®‹å·®
            R_ref = R_preds[0]
            t_ref = t_preds[0]

            residuals = []
            for i in range(1, len(R_preds)):
                # æ—‹è½¬è¯¯å·® (åº¦)
                R_error = R_ref.T @ R_preds[i]
                angle_error = np.degrees(np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1)))

                # å¹³ç§»è¯¯å·® (mm)
                t_error = np.linalg.norm(t_preds[i] - t_ref) * 1000

                # æ·»åŠ åˆ°æ®‹å·®å‘é‡ï¼ˆå½’ä¸€åŒ–ï¼šæ—‹è½¬æƒé‡ 0.2ï¼Œå¹³ç§»æƒé‡ 0.8ï¼‰
                residuals.append(angle_error * 10.0 * 0.2)  # æ—‹è½¬: 1Â° = 10mm
                residuals.append(t_error * 0.8)              # å¹³ç§»: mm

            return np.array(residuals)

        # åˆå§‹å‚æ•°
        rvec_init, _ = cv2.Rodrigues(R_initial)
        tvec_init = t_initial.flatten()
        params_init = np.concatenate([rvec_init.flatten(), tvec_init])

        # è®¡ç®—åˆå§‹æ®‹å·®
        residuals_before = residual_function(params_init)
        error_before = np.sum(residuals_before**2)

        # è®¾ç½®è¾¹ç•Œ: å…è®¸å¾®è°ƒ (Â±5Â°, Â±10mm)
        lower_bounds = []
        upper_bounds = []
        for i in range(3):
            # æ—‹è½¬: Â±5Â° â‰ˆ Â±0.087 rad
            lower_bounds.append(rvec_init[i] - 0.087)
            upper_bounds.append(rvec_init[i] + 0.087)
        for i in range(3):
            # å¹³ç§»: Â±10mm = Â±0.01m
            lower_bounds.append(tvec_init[i] - 0.01)
            upper_bounds.append(tvec_init[i] + 0.01)

        # Levenberg-Marquardt ä¼˜åŒ–
        result = least_squares(
            residual_function,
            params_init,
            method='lm',  # Levenberg-Marquardt
            ftol=1e-8,
            xtol=1e-8,
            gtol=1e-8,
            max_nfev=100,
            verbose=0
        )

        # è§£æç»“æœ
        rvec_opt = result.x[:3]
        tvec_opt = result.x[3:6]
        R_opt, _ = cv2.Rodrigues(rvec_opt)
        t_opt = tvec_opt.reshape(3, 1)

        # è®¡ç®—ä¼˜åŒ–åæ®‹å·®
        residuals_after = residual_function(result.x)
        error_after = np.sum(residuals_after**2)

        # å¦‚æœä¼˜åŒ–åæ›´å·®ï¼Œé€€å›åˆå§‹å€¼
        if error_after > error_before:
            if verbose:
                print(f"   âš ï¸  LMä¼˜åŒ–æœªæ”¹å–„ç»“æœï¼Œä½¿ç”¨åˆå§‹å€¼")
                print(f"   ä¼˜åŒ–å‰: {error_before:.3f}, ä¼˜åŒ–å: {error_after:.3f}")
            return R_initial, t_initial
        else:
            improvement = (error_before - error_after) / error_before * 100
            if verbose:
                print(f"   âœ… LMä¼˜åŒ–æˆåŠŸ: {error_before:.3f} â†’ {error_after:.3f} (æ”¹å–„{improvement:.1f}%)")
                print(f"   è¿­ä»£æ¬¡æ•°: {result.nfev}, çŠ¶æ€: {result.status} ({result.message})")
            return R_opt, t_opt

    @staticmethod
    def levenberg_marquardt_optimization_with_mode(R_initial, t_initial, R_gripper2base,
                                                    t_gripper2base, R_target2cam, t_target2cam,
                                                    mode='eye_in_hand', verbose=True):
        """Levenberg-Marquardt ä¼˜åŒ– - æ”¯æŒä¸¤ç§æ¨¡å¼

        Args:
            R_initial: åˆå§‹æ—‹è½¬çŸ©é˜µ
            t_initial: åˆå§‹å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            mode: 'eye_in_hand' æˆ– 'eye_to_hand'
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            tuple: (R_optimized, t_optimized)
        """
        # Eye-to-hand: è½¬æ¢åæ ‡
        if mode == 'eye_to_hand':
            R_A, t_A = HandEyeCalibration.invert_transformations(
                R_gripper2base, t_gripper2base
            )
        else:
            R_A, t_A = R_gripper2base, t_gripper2base

        # è°ƒç”¨ LM ä¼˜åŒ–ç®—æ³•
        return HandEyeCalibration.levenberg_marquardt_optimization(
            R_initial, t_initial, R_A, t_A,
            R_target2cam, t_target2cam, verbose=verbose
        )

    @staticmethod
    def evaluate_calibration(R_cam2gripper, t_cam2gripper, R_gripper2base,
                            t_gripper2base, R_target2cam, t_target2cam,
                            verbose=True):
        """è¯„ä¼°æ ‡å®šç»“æœè´¨é‡

        è®¡ç®—ä½å§¿é‡å¤æ€§è¯¯å·®å’Œç¨³å®šæ€§

        Args:
            R_cam2gripper: ç›¸æœºåˆ°å¤¹çˆªçš„æ—‹è½¬çŸ©é˜µ
            t_cam2gripper: ç›¸æœºåˆ°å¤¹çˆªçš„å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            dict: è¯„ä¼°ç»“æœ
        """
        # è®¡ç®—æ¯å¸§ä¸‹targetåœ¨baseåæ ‡ç³»çš„ä½å§¿
        R_preds = []
        t_preds = []

        for i in range(len(R_gripper2base)):
            R_pred = R_gripper2base[i] @ R_cam2gripper @ R_target2cam[i]
            t_pred = R_gripper2base[i] @ (R_cam2gripper @ t_target2cam[i] + t_cam2gripper) + t_gripper2base[i]
            R_preds.append(R_pred)
            t_preds.append(t_pred)

        # è®¡ç®—é‡å¤æ€§è¯¯å·®
        R_ref = R_preds[0]
        t_ref = t_preds[0]

        t_errors = []
        r_errors = []

        for i in range(1, len(R_preds)):
            # å¹³ç§»è¯¯å·® (mm)
            t_error = np.linalg.norm(t_preds[i] - t_ref) * 1000
            t_errors.append(t_error)

            # æ—‹è½¬è¯¯å·® (åº¦)
            R_error = R_ref.T @ R_preds[i]
            angle = np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1))
            r_error = np.degrees(angle)
            r_errors.append(r_error)

        # ç»Ÿè®¡é‡
        result = {
            'translation_error_mm': {
                'mean': np.mean(t_errors),
                'std': np.std(t_errors),
                'max': np.max(t_errors),
                'median': np.median(t_errors)
            },
            'rotation_error_deg': {
                'mean': np.mean(r_errors),
                'std': np.std(r_errors),
                'max': np.max(r_errors),
                'median': np.median(r_errors)
            }
        }

        # è´¨é‡è¯„çº§
        avg_t = result['translation_error_mm']['mean']
        avg_r = result['rotation_error_deg']['mean']

        if avg_t < 2.0 and avg_r < 0.3:
            quality = "ä¼˜ç§€"
        elif avg_t < 5.0 and avg_r < 0.5:
            quality = "è‰¯å¥½"
        elif avg_t < 10.0 and avg_r < 1.0:
            quality = "åˆæ ¼"
        else:
            quality = "è¾ƒå·®"

        result['quality'] = quality

        if verbose:
            print(f"\nğŸ“Š æ ‡å®šè´¨é‡è¯„ä¼°:")
            print(f"  ä½å§¿é‡å¤æ€§:")
            print(f"    å¹³ç§»: {avg_t:.2f}Â±{result['translation_error_mm']['std']:.2f}mm (max={result['translation_error_mm']['max']:.2f}mm)")
            print(f"    æ—‹è½¬: {avg_r:.3f}Â±{result['rotation_error_deg']['std']:.3f}Â° (max={result['rotation_error_deg']['max']:.3f}Â°)")
            print(f"  è´¨é‡è¯„çº§: {quality}")

        return result


# ============================================================================
# è¯¯å·®åˆ†æå·¥å…·
# ============================================================================

class ErrorAnalyzer:
    """è¯¯å·®åˆ†æå·¥å…·"""

    @staticmethod
    def analyze_error_patterns(R_cam2gripper, t_cam2gripper, R_gripper2base,
                               t_gripper2base, R_target2cam, t_target2cam,
                               frame_ids):
        """åˆ†æè¯¯å·®æ¨¡å¼,è¯†åˆ«å¼‚å¸¸å¸§

        Args:
            R_cam2gripper: ç›¸æœºåˆ°å¤¹çˆªçš„æ—‹è½¬çŸ©é˜µ
            t_cam2gripper: ç›¸æœºåˆ°å¤¹çˆªçš„å¹³ç§»å‘é‡
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            R_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„æ—‹è½¬åˆ—è¡¨
            t_target2cam: æ ‡é¶åˆ°ç›¸æœºçš„å¹³ç§»åˆ—è¡¨
            frame_ids: å¸§IDåˆ—è¡¨

        Returns:
            dict: è¯¯å·®åˆ†æç»“æœ
        """
        # è®¡ç®—æ¯å¸§çš„ä½å§¿é¢„æµ‹
        R_preds = []
        t_preds = []

        for i in range(len(R_gripper2base)):
            R_pred = R_gripper2base[i] @ R_cam2gripper @ R_target2cam[i]
            t_pred = R_gripper2base[i] @ (R_cam2gripper @ t_target2cam[i] + t_cam2gripper) + t_gripper2base[i]
            R_preds.append(R_pred)
            t_preds.append(t_pred)

        # ä»¥ç¬¬ä¸€å¸§ä¸ºå‚è€ƒ
        R_ref = R_preds[0]
        t_ref = t_preds[0]

        # è®¡ç®—æ¯å¸§è¯¯å·®
        frame_errors = []
        for i in range(1, len(R_preds)):
            t_error = np.linalg.norm(t_preds[i] - t_ref) * 1000
            R_error = R_ref.T @ R_preds[i]
            r_error = np.degrees(np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1)))

            frame_errors.append({
                'frame_id': frame_ids[i],
                'translation_error_mm': t_error,
                'rotation_error_deg': r_error,
                'total_error': t_error + r_error * 10.0  # 1Â° = 10mm
            })

        # æŒ‰è¯¯å·®æ’åº
        frame_errors.sort(key=lambda x: x['total_error'], reverse=True)

        # è¯†åˆ«å¼‚å¸¸å¸§ (è¶…è¿‡ä¸­ä½æ•° + 2å€MAD)
        errors = np.array([fe['total_error'] for fe in frame_errors])
        median = np.median(errors)
        mad = np.median(np.abs(errors - median))
        threshold = median + 2.0 * mad

        outliers = [fe for fe in frame_errors if fe['total_error'] > threshold]

        return {
            'frame_errors': frame_errors,
            'outliers': outliers,
            'outlier_threshold': threshold,
            'worst_frames': frame_errors[:5]  # æœ€å·®çš„5å¸§
        }

    @staticmethod
    def check_motion_diversity(R_gripper2base, t_gripper2base, verbose=True):
        """æ£€æŸ¥è¿åŠ¨å¤šæ ·æ€§

        Args:
            R_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬åˆ—è¡¨
            t_gripper2base: æœºå™¨äººæœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            dict: è¿åŠ¨å¤šæ ·æ€§åˆ†æç»“æœ
        """
        # è®¡ç®—ä½ç§»èŒƒå›´
        positions = np.array([t.flatten() for t in t_gripper2base])
        pos_range = positions.max(axis=0) - positions.min(axis=0)
        pos_range_mm = pos_range * 1000

        # è®¡ç®—æ—‹è½¬èŒƒå›´
        euler_angles = []
        for R_mat in R_gripper2base:
            r = R.from_matrix(R_mat)
            euler = r.as_euler('xyz', degrees=True)
            euler_angles.append(euler)

        euler_angles = np.array(euler_angles)
        rot_range = euler_angles.max(axis=0) - euler_angles.min(axis=0)

        result = {
            'position_range_mm': pos_range_mm,
            'rotation_range_deg': rot_range,
            'sufficient_motion': (pos_range_mm > 50).all() and (rot_range > 10).all()
        }

        if verbose:
            print(f"\nğŸ¯ è¿åŠ¨å¤šæ ·æ€§:")
            print(f"  ä½ç§»èŒƒå›´: X={pos_range_mm[0]:.1f}mm, Y={pos_range_mm[1]:.1f}mm, Z={pos_range_mm[2]:.1f}mm")
            print(f"  æ—‹è½¬èŒƒå›´: Roll={rot_range[0]:.1f}Â°, Pitch={rot_range[1]:.1f}Â°, Yaw={rot_range[2]:.1f}Â°")
            print(f"  è¿åŠ¨å……åˆ†: {'âœ…' if result['sufficient_motion'] else 'âŒ'}")

        return result
